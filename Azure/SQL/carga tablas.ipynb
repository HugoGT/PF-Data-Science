{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primera tarea de Airflow\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "\n",
    "from keys import (\n",
    "    PGHOST,\n",
    "    PGUSER,\n",
    "    PGPORT,\n",
    "    PGDATABASE,\n",
    "    PGPASSWORD,\n",
    "    AZURE_STORAGE_NAME,\n",
    "    AZURE_STORAGE_KEY,\n",
    "    AZURE_CONTAINER_NAME,\n",
    "    AZURE_BLOB_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos de conexión a PostgreSQL\n",
    "pg_host = PGHOST\n",
    "pg_user = PGUSER\n",
    "pg_port = PGPORT\n",
    "pg_database = PGDATABASE\n",
    "pg_password = PGPASSWORD\n",
    "\n",
    "# Datos de conexión al datalake\n",
    "storage_account_name = AZURE_STORAGE_NAME\n",
    "storage_account_key = AZURE_STORAGE_KEY\n",
    "container_name = AZURE_CONTAINER_NAME\n",
    "blob_name = AZURE_BLOB_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_from_datalake(blob_name):\n",
    "    connection_string = f\"DefaultEndpointsProtocol=https;AccountName={storage_account_name};AccountKey={storage_account_key};EndpointSuffix=core.windows.net\"\n",
    "    blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
    "    container_client = blob_service_client.get_container_client(container_name)\n",
    "    blob_client = container_client.get_blob_client(blob_name)\n",
    "    data = blob_client.download_blob().readall().decode(\"utf-8\")\n",
    "    df = pd.read_csv(pd.io.common.StringIO(data))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TABLA DAÑOS\n",
    "def load_danios():\n",
    "    # Insertar o actualizar los datos en PostgreSQL\n",
    "    data = read_data_from_datalake(\"daños_final.csv\")\n",
    "    data.drop_duplicates(subset='id_danio', inplace=True)\n",
    "\n",
    "    # Conexión a PostgreSQL\n",
    "    conn = psycopg2.connect(\n",
    "        host=pg_host,\n",
    "        port=pg_port,\n",
    "        database=pg_database,\n",
    "        user=pg_user,\n",
    "        password=pg_password\n",
    "    )\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Preparar la consulta SQL de inserción\n",
    "    insert_query = \"INSERT INTO danios (id_danio, fecha, estado, afectados, desaparecidos, heridos, viv_destr, viv_afect, id_sismo) VALUES\\n\"\n",
    "    values_query = []\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        id_danio = row[0]\n",
    "        fecha = row[1]\n",
    "        estado = row[2]\n",
    "        afectados = row[3]\n",
    "        desaparecidos = row[4]\n",
    "        heridos = row[5]\n",
    "        viv_destr = row [6]\n",
    "        viv_afect = row[7]\n",
    "        id_sismo = row[8]\n",
    "        values = f\"({id_danio}, '{fecha}', '{estado}', {afectados}, {desaparecidos}, {heridos}, {viv_destr}, {viv_afect}, {id_sismo}),\\n\"\n",
    "        values_query.append(values)\n",
    "\n",
    "    query = insert_query + ''.join(values_query)[:-2] + \";\"\n",
    "\n",
    "    # Ejecutar la consulta de inserción\n",
    "    cursor.execute(query)\n",
    "\n",
    "    # Cerrar la conexión a PostgreSQL\n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TABLA LUGAR\n",
    "def load_lugar():\n",
    "    # Insertar o actualizar los datos en PostgreSQL\n",
    "    data = read_data_from_datalake(\"lugar.csv\")\n",
    "\n",
    "    # Conexión a PostgreSQL\n",
    "    conn = psycopg2.connect(\n",
    "        host=pg_host,\n",
    "        port=pg_port,\n",
    "        database=pg_database,\n",
    "        user=pg_user,\n",
    "        password=pg_password\n",
    "    )\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Preparar la consulta SQL de inserción\n",
    "    insert_query = \"INSERT INTO lugar (id_lugar, pais, estado) VALUES\\n\"\n",
    "    values_query = []\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        id_lugar = row[0]\n",
    "        pais = row[1]\n",
    "        estado = row[2]\n",
    "        values = f\"({id_lugar}, '{pais}', '{estado}'),\\n\"\n",
    "        values_query.append(values)\n",
    "\n",
    "    query = insert_query + ''.join(values_query)[:-2] + \";\"\n",
    "\n",
    "    # Ejecutar la consulta de inserción\n",
    "    cursor.execute(query)\n",
    "\n",
    "    # Cerrar la conexión a PostgreSQL\n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TABLA TSUNAMIS\n",
    "def load_tsunamis():\n",
    "    # Insertar o actualizar los datos en PostgreSQL\n",
    "    data = read_data_from_datalake(\"tsunamis.csv\")\n",
    "\n",
    "    # Conexión a PostgreSQL\n",
    "    conn = psycopg2.connect(\n",
    "        host=pg_host,\n",
    "        port=pg_port,\n",
    "        database=pg_database,\n",
    "        user=pg_user,\n",
    "        password=pg_password\n",
    "    )\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Preparar la consulta SQL de inserción\n",
    "    insert_query = \"INSERT INTO tsunamis (id_tsunami, fecha, hora, max_water_height, id_sismo, estado, pais) VALUES\\n\"\n",
    "    values_query = []\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        id_tsunami = row[0]\n",
    "        fecha = row[1]\n",
    "        hora = row[2]\n",
    "        max_water_height = row[3]\n",
    "        id_sismo = row[4]\n",
    "        estado = row[5]\n",
    "        pais = row[6]\n",
    "        values = f\"({id_tsunami}, '{fecha}', '{hora}', {max_water_height}, {id_sismo}, '{estado}', '{pais}'),\\n\"\n",
    "        values_query.append(values)\n",
    "\n",
    "    query = insert_query + ''.join(values_query)[:-2] + \";\"\n",
    "\n",
    "    # Ejecutar la consulta de inserción\n",
    "    cursor.execute(query)\n",
    "\n",
    "    # Cerrar la conexión a PostgreSQL\n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TABLA TSUNAMIS\n",
    "def load_sismos():\n",
    "    # Insertar o actualizar los datos en PostgreSQL\n",
    "    data = read_data_from_datalake(\"sismos_completo.csv\")\n",
    "    data['estado'] = data['estado'].replace('Mar de USA', 'Mar de EEUU')\n",
    "\n",
    "    # Conexión a PostgreSQL\n",
    "    conn = psycopg2.connect(\n",
    "        host=pg_host,\n",
    "        port=pg_port,\n",
    "        database=pg_database,\n",
    "        user=pg_user,\n",
    "        password=pg_password\n",
    "    )\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Preparar la consulta SQL de inserción\n",
    "    insert_query = \"INSERT INTO sismos (fecha, hora, latitud, longitud, profundidad, magnitud, pais, estado) VALUES\\n\"\n",
    "    values_query = []\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        fecha = row[1]\n",
    "        hora = row[2]\n",
    "        latitud = row[3]\n",
    "        longitud = row[4]\n",
    "        profundidad = row[5]\n",
    "        magnitud = row[6]\n",
    "        pais = row[7]\n",
    "        estado = row[8]\n",
    "        values = f\"('{fecha}', '{hora}', {latitud}, {longitud}, {profundidad}, {magnitud}, '{pais}', '{estado}'),\\n\"\n",
    "        values_query.append(values)\n",
    "\n",
    "    query = insert_query + ''.join(values_query)[:-2] + \";\"\n",
    "\n",
    "    # Ejecutar la consulta de inserción\n",
    "    cursor.execute(query)\n",
    "\n",
    "    # Cerrar la conexión a PostgreSQL\n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este archivo será la task_0 airflow"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
